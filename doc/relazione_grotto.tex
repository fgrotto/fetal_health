\documentclass[a4paper,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage{fullpage,graphicx,psfrag,amsmath,amsfonts}
\usepackage[small,bf]{caption}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{lipsum}
\usepackage{url}
\usepackage{fancyvrb}
\usepackage{bm}
\usepackage{float}
% \usepackage{mathptmx}
\usepackage[p,osf]{cochineal}
\usepackage{listings}
\usepackage[varqu,varl,var0]{inconsolata}
\usepackage[scale=.95,type1]{cabin}
\usepackage[cochineal,vvarbb]{newtxmath}
\usepackage[cal=boondoxo]{mathalfa}
\usepackage{enumitem}
\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}
\begin{document}
\author{Filippo Grotto VR460638}

\title{Fetal Health Classification  \\[1ex] \large Machine Learning and Artificial Intelligence \\[1ex] \large Academic year 2020/2021}

\maketitle
\newpage
\tableofcontents
\newpage

\section{Motivation and rationale}
This project is heavily inspired by a kaggle task \cite{kaggle} about fetal health classification.
\begin{quote}
Reduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals and is a key indicator of human progress.
The UN expects that by 2030, countries end preventable deaths of newborns and children under 5 years of age, with all countries aiming to reduce under‑5 mortality to at least as low as 25 per 1,000 live births.

Parallel to notion of child mortality is of course maternal mortality, which accounts for 295 000 deaths during and following pregnancy and childbirth (as of 2017). The vast majority of these deaths (94\%) occurred in low-resource settings, and most could have been prevented.

In light of what was mentioned above, Cardiotocograms (CTGs) are a simple and cost accessible option to assess fetal health, allowing healthcare professionals to take action in order to prevent child and maternal mortality. The equipment itself works by sending ultrasound pulses and reading its response, thus shedding light on fetal heart rate (FHR), fetal movements, uterine contractions and more.
\end{quote}
In this context this project is not only an application of machine learning techniques but it also have some meaningful application into real world scenarios thanks to the real data provided.


\section{Problem definition and Dataset}
The dataset comes from UCI Machine Learning Repository \cite{uci} and it is composed by 
\begin{quote}
2126 fetal cardiotocograms (CTGs) automatically processed with the respective diagnostic features measured. The CTGs are were classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N=normal; S=suspect; P=pathologic). Therefore the dataset can be used either for 10-class or 3-class experiments.
\end{quote}
We will address the 3-class classification problem so we will try to classify the data according to normal, suspect or pathologic.

\section{Methodology}
The classification problem is addressed using the following techniques:

\begin{itemize}
  \item Naive Bayes \cite{ml}
  \item SVM (with different kernels linear and RBF ) \cite{ml}
  \item KNN (with different k based on preliminary analysis) \cite{ml}
  \item ANN \cite{ann}
\end{itemize}
Moreover, PCA and Fisher (LDA) dimensionality reduction techniques are considered as well as the effects of data scaling and/or normalization. We don't expect to see improvements of the state of the art where other techniques (XGBoost, Random forests, Decision tree models) are used.

\section{Experiments and Results}
\subsection{Dataset exploration}
The dataset is composed by 2126 entries with 22 features (21 feature + fetal health which is our target for the classification). From a first analysis there are no null or empty values but there are 13 duplications which we dropped. A brief description of the dataset is reported in Fig \ref{fig:features}.

\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\textwidth]{images/features.png}
\end{center}
\caption{Description of all feature dataset}
\label{fig:features}
\end{figure}

\noindent Another observation to make is the presence of high class imbalance that comes from the real dataset. In Fig \ref{fig:imbalance} it is visible that \textbf{Normal} represents around the 78\% of the entire dataset.

\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\textwidth]{images/imbalance.png}
\end{center}
\caption{Class imbalance in the dataset, around 78\% is classified as normal fetal health}
\label{fig:imbalance}
\end{figure}

\noindent Having verified the presence of class imbalance we will use different performance measures for our models in order to avoid misleading considerations:
\bigbreak
\begin{itemize}
  \item \textbf{Precision}
  \item \textbf{Accuracy}
  \item \textbf{Recall}
  \item \textbf{Confusion Matrix}
  \item \textbf{F1 Score}
\end{itemize}

\bigbreak
\noindent Finally we can analyse the correlation between features of the dataset in order to evaluate a possible subset to improve our performances.
In Fig \ref{fig:correlation} a heatmap is reported with the correlation between our features. In table \ref{tab:correlation} the features with more than 30\% correlation with \textbf{fetal health} are reported

\begin{table}[H]
\begin{tabular}{ |p{10cm}||p{3cm}| }
  \hline
  Feature Name& Correlation \\
  \hline
  accelerations&                                            -0.364066\\
  prolongued decelerations&                                  0.484859\\
  abnormal short term variability&                           0.471191\\
  percentage of time with abnormal long term variability&    0.426146\\
  \hline
\end{tabular}
\caption{Feature with correlation higher than 30\%}
\label{tab:correlation}
\end{table}

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=1.0\textwidth]{images/correlation.png}
  \end{center}
  \caption{Correlation between features}
  \label{fig:correlation}
\end{figure}

\noindent As a result the features with high correlation are \textbf{accelerations}, \textbf{prolongued decelerations},\textbf{abnormal short term variability} and \textbf{percentage of time with abnormal long term variability}. They will be considered in a further analysis as a reasonable subset of the dataset to exploit our models.

\subsection{Data scaling}
In Fig \ref{fig:notscaled} the original data is reported. It's visible that the data requires a proper scaling to avoid the presence of dominant features that might affect our analysis. In Fig \ref{fig:scaled} the scaled data is reported where \textbf{StandardScaler} was used. Data normalization is not actually reported since from experiments it doesn't provide much more benefits and it's irrelevant for the sake of this report.

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.8\textwidth]{images/not_scaledù.png}
  \end{center}
  \caption{Plot of the original data without scaling}
  \label{fig:notscaled}
\end{figure}

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.8\textwidth]{images/scaled.png}
  \end{center}
  \caption{Plot of the scaled data}
  \label{fig:scaled}
\end{figure}

\newpage
\subsection{PCA dimensionality reduction}
\bigbreak
\noindent In Fig \ref{fig:pca} the analysis of PCA dimensionality reduction is considered. In particular the graph rappresents the cumulative explained variation ratio with respect of all the possible components we might want to consider.

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=1.0\textwidth]{images/pca.png}
  \end{center}
  \caption{PCA cumulative explained variance ratio wrt of components}
  \label{fig:pca}
\end{figure}

\noindent In particular the last five components don't provide much more information (close to zero) and with 8 components we have a representation of around 80\% of our dataset. In table \ref{tab:pca} the results obtained by our models over the 8 components is provided.

\begin{table}[H]
  \begin{tabular}{ |p{6cm}||p{2cm}|p{2cm}|p{2cm}|p{2cm}| }
    \hline
    Model& accuracy & precision  &  recall & f1 score \\
    \hline
SVM linear&           0.899687&   0.898669&  0.899687&  0.899022\\
SVM poly   &          0.891850&   0.885607&  0.891850&  0.885699\\
SVM rbf     &         0.905956&   0.902835&  0.905956&  0.903968\\
SVM sigmoid  &        0.717868&   0.765628&  0.717868&  0.737608\\
Gaussian Naive  &        0.862069&   0.865387&  0.862069&  0.861556\\
Logistic Regression&  0.899687&   0.897470&  0.899687&  0.898194\\
    \hline
  \end{tabular}
  \caption{Evaluation of our models over 8 PCA components}
  \label{tab:pca}
  \end{table}

\newpage
\subsection{LDA dimensionality reduction}

In this section a brief analysis of Linear Discriminant Analysis is reported in Fig \ref{fig:lda} where we can easily see that the cumulative variance ratio accumulated with 1 component rappresents more than 80\% of our dataset
Moreover, both the case with 1 and 2 components are reported in the two tables \ref{tab:lda1} and \ref{tab:lda2}. 

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.8\textwidth]{images/lda.png}
  \end{center}
  \caption{LDA cumulative explained variance ratio wrt of components}
  \label{fig:lda}
\end{figure}


\begin{table}[H]
\begin{tabular}{ |p{6cm}||p{2cm}|p{2cm}|p{2cm}|p{2cm}| }
  \hline
  Model& accuracy & precision  &  recall & f1 score \\
  \hline
  SVM linear&           0.847962&   0.829295&  0.847962&  0.828071\\
  SVM poly  &           0.841693&   0.820448&  0.841693&  0.802800\\
  SVM rbf   &           0.846395&   0.832120&  0.846395&  0.836413\\
  SVM sigmoid &         0.766458&   0.776691&  0.766458&  0.771115\\
  Gaussian Naive  &        0.854232&   0.847738&  0.854232&  0.850451\\
  Logistic Regression & 0.844828&   0.828893&  0.844828&  0.832487\\
  \hline
\end{tabular}
\caption{Evaluation of our models with 1 LDA component}
\label{tab:lda1}
\end{table}

\begin{table}[H]
\begin{tabular}{ |p{6cm}||p{2cm}|p{2cm}|p{2cm}|p{2cm}| }
  \hline
  Model& accuracy & precision  &  recall & f1 score \\
  \hline
  SVM linear &          0.898119&   0.898106&  0.898119&  0.898103\\
  SVM poly   &          0.899687&   0.895180&  0.899687&  0.894518\\
  SVM rbf    &          0.905956&   0.907072&  0.905956&  0.906281\\
  SVM sigmoid &         0.689655&   0.725761&  0.689655&  0.704979\\
  Gaussian Naive &         0.873041&   0.885894&  0.873041&  0.877463\\
  Logistic Regression&  0.902821&   0.898863&  0.902821&  0.899858\\
  \hline
\end{tabular}
\caption{Evaluation of our models with 2 LDA components}
\label{tab:lda2}
\end{table}


\noindent In general in case of uniformly distributed data, LDA almost always performs better than PCA. However if the data is highly skewed (irregularly distributed) then it is advised to use PCA since LDA can be biased towards the majority class.

\newpage
\subsection{Model evaluations with the full dataset}

In this section the evaluations of several models are presented. For all of the the dataset has been divided using $train\_test\_split$ function from sklearn using around 30\% of the entire dataset for the testing set. 
The results of our models are reported in Fig \ref{fig:fulldataset}. It's visible that SVM with rbf kernel produces the best results over our dataset. This is coherent with the analysis in \cite{ml} and what the literature provides us about Support Vector Machines Kernels. Let's consider:
\bigbreak
\begin{itemize}
  \item 1.0 is Normal class
  \item 2.0 is Suspicious class
  \item 3.0 is Pathologic class
\end{itemize} 

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=1.0\textwidth]{images/fulldataset.png}
  \end{center}
  \caption{Results of the selected models over our dataset}
  \label{fig:fulldataset}
\end{figure}

\noindent From a brief analysis we can clearly see that SVM in general works pretty well over our dataset, Naive Bayes, Logistic Regression and SVM with sigmoid kernel are pretty bad in terms of precision for \textbf{suspicious} and \textbf{pathologic}. In general the class \textbf{Normal} has better performances due to the class imbalance (more than 78\%). Moreover in Fig \ref{fig:confusion_svm} the confusion matrix for the svm with rbf kernel is reported and in Fig \ref{fig:confusion_bayes}. What is clearly visible is the fact that for SVM with rbf there are close to zero false positive and false negative values which is a pretty good result. For Naive Bayes we have a false negative value which is even higher than the true value which is pretty bad for our classification problem.

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.8\textwidth]{images/svm_rbf.png}
  \end{center}
  \caption{Confusion matrix of SVM with rbf kernel}
  \label{fig:confusion_svm}
\end{figure}

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.8\textwidth]{images/confusion_naive.png}
  \end{center}
  \caption{Confusion matrix of Naive Bayes approach}
  \label{fig:confusion_bayes}
\end{figure}

\subsubsection{K-Nearest Neighbors}
In this section we will consider the use of K-NN (with an euclidean distance applied) to our dataset. In Fig \ref{fig:knn} a brief analysis of several k is provided with the related metrics to get an idea of which are the most promising values of K to use.

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=1.0\textwidth]{images/knn.png}
  \end{center}
  \caption{K-NN metrics with respect of the value K-neighbors}
  \label{fig:knn}
\end{figure}

\noindent As a result the values K = 2 and K = 4 are the best choices which is very close to what the literature provides use which is $\sqrt{N}$ where $N$ is the number of features. In this case $\sqrt{21} = 4.6$ which is pretty close to what we get from the practical analysis. In Table \ref{tab:knnres} the two best cases are considered and analysed.

\begin{table}[H]
\begin{tabular}{ |p{6cm}||p{2cm}|p{2cm}|p{2cm}|p{2cm}| }
  \hline
  Model& accuracy & precision  &  recall & f1 score \\
  \hline
  K-NN with k=2 &          0.90&   0.90&  0.90&  0.89\\
  K-NN with k=4   &          0.91&   0.91&  0.91&  0.91\\
  \hline
\end{tabular}
\caption{Evaluation of K-NN models}
\label{tab:knnres}
\end{table}

\noindent As a conclusion K-NN with k=4 or k=2 are great models for our analysis

\newpage
\subsubsection{Artificial Neural Networks MLP}
In this section we will brief provide some results obtained by using Artificial Neural Networks to solve the classification problem. In particular we created a multilayer perceptron (MLP) with the following parameters
\begin{Verbatim}[fontsize=\small]
input_size = 21
hidden_size = 100
num_classes = 3
num_epochs = 100
batch_size = 50
learning_rate = 0.001
\end{Verbatim} 

\begin{Verbatim}[fontsize=\small]
# Fully connected neural network with one hidden layer
class NeuralNet(nn.Module):
  def __init__(self, input_size, hidden_size, num_classes):
      super(NeuralNet, self).__init__()
      self.fc1 = nn.Linear(input_size, hidden_size) 
      self.relu = nn.ReLU()
      self.fc2 = nn.Linear(hidden_size, num_classes)  
  
  def forward(self, x):
      out = self.fc1(x)
      out = self.relu(out)
      out = self.fc2(out)
      return out
\end{Verbatim}

\noindent The MLP uses one fully connected layer, a ReLU as activation function and another fully connected layer (Linear). This models proved to have an accuracy around 91\% which makes it a good model for the classification task as reported in Fig \ref{fig:annres}. In Fig \ref{fig:anntrain} the train accuracies and losses are reported.

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.6\textwidth]{images/ann_res.png}
  \end{center}
  \caption{Results of the MPL network}
  \label{fig:annres}
\end{figure}


\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.6\textwidth]{images/ann_train.png}
  \end{center}
  \caption{Accuracy and losses of the MLP}
  \label{fig:anntrain}
\end{figure}

\subsection{Other Exploratory Tasks}

\subsubsection{Models evaluation using a subset of features}

In this section an evaluation of our models over a subset of features defined in the previous section is presented. Only features with more than 30\% correlation with the target \textbf{fetal health} are used. They are reported in Table \ref{tab:correlation}. In Table \ref{tab:subset} the evaluation of our models is reported according to the defined metrics. Moreover, in Fig \ref{fig:poly} the classification report for the best model SVM poly is reported.

\begin{table}[H]
\begin{tabular}{ |p{6cm}||p{2cm}|p{2cm}|p{2cm}|p{2cm}| }
  \hline
  Model& accuracy & precision  &  recall & f1 score \\
  \hline
  SVM linear &          0.85&   0.85&  0.84&  0.85\\
  SVM poly   &          0.90&   0.90&  0.90&  0.90\\
  SVM rbf    &          0.88&   0.88&  0.88&  0.88\\
  SVM sigmoid &         0.82&   0.82&  0.82&  0.82\\
  Gaussian Naive &         0.84&   0.84&  0.86&  0.84\\
  Logistic Regression&  0.88&   0.88&  0.88&  0.88\\
  \hline
\end{tabular}
\caption{Evaluation of our models over a subset of features}
\label{tab:subset}
\end{table}

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=1.0\textwidth]{images/svm_poly.png}
  \end{center}
  \caption{Detailed classification report for SVM with polynomial kernel}
  \label{fig:poly}
\end{figure}

\noindent Finally it's visible from the report that the class imbalance plays again an important role and the f1-score for the \textbf{Suspicious} class is very low if compared with the other two classes. Anyway we showed how using a lower number of features we are still able to get pretty good results and having a good confusion matrix (very low number of false positive an negative).

\subsubsection{Semisupervised Problem}
In this section the semisupervised problem is briefly approached using a simple pseudo labelling method. We are going to use 100 samples per each class. The results for the semisupervised problem are reported in Fig \ref{fig:semi}, the results for the fully supervised problem are reported in Fig \ref{fig:fully}  

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=1.0\textwidth]{images/semi.png}
  \end{center}
  \caption{Classification report for the semisupervised problem using OneVsOne SVM with linear kernel}
  \label{fig:semi}
\end{figure}

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=1.0\textwidth]{images/fully.png}
  \end{center}
  \caption{Classification report for the fully supervised problem using OneVsOne SVM with linear kernel}
  \label{fig:fully}
\end{figure}

\noindent What is clearly visible is the fact that using a semisupervised approach we have less precision with the second class \textbf{Suspicious} due to the strong class imbalance. In fact we are introducing some false negatives that are visible in the confusion matrix.

\section{Conclusion}

In this report the study of the classification health of the fetal has been analysed using a real dataset. Several different models have been analysed using different metrics and different dimensionality reduction methodology. It is showed how using SVM with rbf kernel and 17 PCA components produces the best results. Finally, several other classification methods has been exploited and compared using different metrics. 

\newpage
\begin{thebibliography}{9}
\bibitem{cardio}
Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms

\bibitem{kaggle}
Fetal Health Classification https://www.kaggle.com/andrewmvd/fetal-health-classification

\bibitem{uci}
Cardiocotography dataset https://archive.ics.uci.edu/ml/datasets/cardiotocography

\bibitem{ml}
Hoodbhoy, Zahra et al. “Use of Machine Learning Algorithms for Prediction of Fetal Risk using Cardiotocographic Data.”

\bibitem{ann}
Yılmaz, E. Fetal State Assessment from Cardiotocogram Data Using Artificial Neural Networks.

\end{thebibliography}
\end{document}